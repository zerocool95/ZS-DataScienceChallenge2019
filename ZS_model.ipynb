{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "# from tqdm.auto import tqdm\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "tqdm.pandas(tqdm_notebook)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, Imputer\n",
    "from sklearn.preprocessing import LabelEncoder, Imputer\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error\n",
    "\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import collections\n",
    "\n",
    "import random\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = pd.read_csv('data/data.csv')\n",
    "total_data.drop('Unnamed: 0', inplace = True,axis =1 )\n",
    "total_data['shot_id_number'] = range(1,30698)\n",
    "data_test = total_data[total_data.is_goal.isnull()]\n",
    "data_train = total_data[~total_data.is_goal.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train_size : \", data_train.shape[0])\n",
    "print(\"Test_size : \", data_test.shape[0])\n",
    "print(\"Total_size : \", total_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autolabel(rects, ax):\n",
    "    \"\"\"\n",
    "    Attach a text label above each bar displaying its height\n",
    "    \"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width()/2., height,\n",
    "                '%d' % int(height),\n",
    "                ha='center', va='bottom')\n",
    "        \n",
    "def show_unique_and_nans(df):\n",
    "    df_temp = pd.DataFrame(columns=['Name', 'Unique_Values', 'NaNs'])\n",
    "    for i, col in enumerate(df.columns):\n",
    "        df_temp.loc[i] = [col, df[col].nunique(), df[col].isna().sum()]\n",
    "    df_temp.index = df_temp['Name']\n",
    "    df_temp.drop('Name', inplace=True, axis = 1)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize = (15,5))\n",
    "    width = 0.35\n",
    "    ind = np.arange(len(df.columns))\n",
    "    rects1 = ax.bar(ind, df_temp.Unique_Values, width, color='r')\n",
    "    rects2 = ax.bar(ind + width, df_temp.NaNs, width, color='y')\n",
    "    ax.set_ylabel('Number of values')\n",
    "    ax.set_title('Unique values and NaNs in every column')\n",
    "    ax.set_xticks(ind + width / 2)\n",
    "    ax.set_xticklabels(df.columns,  rotation = 90)\n",
    "    ax.legend(['Unique Values', 'NaNs'],loc = \"best\")\n",
    "    autolabel(rects1,ax)\n",
    "    autolabel(rects2, ax)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engg(df):\n",
    "    df['dxp'] = df['power_of_shot'] * df['distance_of_shot']\n",
    "#     df['dxp.1'] = df['power_of_shot.1'] * df['distance_of_shot.1']\n",
    "    \n",
    "#     df['dxp_final'] = (df['power_of_shot'] + df['power_of_shot.1']) * (df['distance_of_shot'] + df['distance_of_shot.1'])\n",
    "    \n",
    "    df['lat'], df['lng'] = df['lat/lng'].str.split(',', 1).str\n",
    "    df['lat'] = df['lat'].astype(np.float64)\n",
    "    df['lng'] = df['lng'].astype(np.float64)\n",
    "#     df['fx'] = df['location_x'] + df['lat']\n",
    "#     df['fy'] = df['location_y'] + df['lng']\n",
    "    \n",
    "    df['tot_remaining_time'] = df['remaining_min'] + df['remaining_sec']\n",
    "#     df['tot_remaining_time.1'] = df['remaining_min.1'] + df['remaining_sec.1']\n",
    "    \n",
    "#     df['total_remaining_time_final'] = df['remaining_min'] + df['remaining_sec'] \\\n",
    "#                                         + df['remaining_min.1'] + df['remaining_sec.1']\n",
    "    df.drop(['power_of_shot.1','distance_of_shot.1', 'remaining_min.1' , 'remaining_sec.1' ], inplace =True , axis = 1)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "def impute_most_frequent(col, df):\n",
    "    df[col] = df[col].fillna(df[col].value_counts().index[0])\n",
    "\n",
    "def impute_mean(col, df):\n",
    "    df[col].fillna(value = df[col].mean(),inplace=True)\n",
    "    \n",
    "def remove_cols(col_list, df):\n",
    "    df.drop(columns = col_list, inplace = True, axis = 1 )\n",
    "    \n",
    "def custom_impute_fun(grp, most_freq_cols):\n",
    "    for col in grp.columns:\n",
    "        if len(grp[col].value_counts()) > 0:\n",
    "            grp[col] = grp[col].fillna(grp[col].value_counts().index[0])\n",
    "        else:\n",
    "            grp[col] = grp[col].fillna(0)\n",
    "    \n",
    "    return grp\n",
    "\n",
    "def isNan(val):\n",
    "    return val != val\n",
    "\n",
    "def impute_values(df, grp_col_name = None):\n",
    "    shot_type_str = []\n",
    "    shot_type_cat = []\n",
    "    \n",
    "    shot_basics = collections.defaultdict(list)\n",
    "    range_of_shot = collections.defaultdict(list)\n",
    "    area_of_shot = collections.defaultdict(list)\n",
    "    \n",
    "    \n",
    "    for i, row in tqdm(df.iterrows(), total = len(df)):\n",
    "        # merging type of shot and combined type into one column and adding a column specifying type\n",
    "        if isNan(row['type_of_shot']):\n",
    "            if isNan(row['type_of_combined_shot']):\n",
    "                shot_type_str.append('None')\n",
    "                shot_type_cat.append(0)\n",
    "            else:\n",
    "                shot_type_str.append(str(row['type_of_combined_shot']))\n",
    "                shot_type_cat.append(1)\n",
    "        else:\n",
    "            shot_type_str.append(str(row['type_of_shot']))\n",
    "            shot_type_cat.append(2)\n",
    "        \n",
    "        ####################\n",
    "        if isNan(row['shot_basics']) == False:\n",
    "            if isNan(row['range_of_shot']) == False:\n",
    "                shot_basics['range_of_shot'].append(row['shot_basics'])\n",
    "            \n",
    "            if isNan(row['area_of_shot']) == False:\n",
    "                shot_basics['area_of_shot'].append(row['shot_basics'])\n",
    "                \n",
    "        if isNan(row['range_of_shot']) == False:\n",
    "            if isNan(row['shot_basics']) == False:\n",
    "                range_of_shot['shot_basics'].append(row['range_of_shot'])\n",
    "            \n",
    "            if isNan(row['area_of_shot']) == False:\n",
    "                range_of_shot['area_of_shot'].append(row['range_of_shot'])\n",
    "                \n",
    "        if isNan(row['area_of_shot']) == False:\n",
    "            if isNan(row['shot_basics']) == False:\n",
    "                area_of_shot['shot_basics'].append(row['area_of_shot'])\n",
    "            \n",
    "            if isNan(row['range_of_shot']) == False:\n",
    "                area_of_shot['range_of_shot'].append(row['area_of_shot'])\n",
    "    \n",
    "    sb = []\n",
    "    ros = []\n",
    "    aos = []\n",
    "    \n",
    "    for i, row in tqdm(df.iterrows(), total = len(df)):\n",
    "        if isNan(row['shot_basics']):\n",
    "            if isNan(row['range_of_shot']) == False:\n",
    "                sb.append(random.choice(shot_basics['range_of_shot']))\n",
    "            \n",
    "            elif isNan(row['area_of_shot']) == False:\n",
    "                sb.append(random.choice(shot_basics['area_of_shot']))\n",
    "                \n",
    "            else:\n",
    "                sb.append(\"None\")\n",
    "        else:\n",
    "            sb.append(row['shot_basics'])\n",
    "                \n",
    "        if isNan(row['range_of_shot']):\n",
    "            if isNan(row['shot_basics']) == False:\n",
    "                ros.append(random.choice(range_of_shot['shot_basics']))\n",
    "            \n",
    "            elif isNan(row['area_of_shot']) == False:\n",
    "                ros.append(random.choice(range_of_shot['area_of_shot']))\n",
    "            else:\n",
    "                ros.append(\"None\")\n",
    "        else:\n",
    "            ros.append(row['range_of_shot'])\n",
    "                \n",
    "        if isNan(row['area_of_shot']):\n",
    "            if isNan(row['range_of_shot']) == False:\n",
    "                aos.append(random.choice(area_of_shot['range_of_shot']))\n",
    "            \n",
    "            elif isNan(row['shot_basics']) == False:\n",
    "                aos.append(random.choice(area_of_shot['shot_basics']))\n",
    "            else:\n",
    "                aos.append(\"None\")\n",
    "        else:\n",
    "            aos.append(row['area_of_shot'])\n",
    "                \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "            \n",
    "    df = df.assign(shot_type=shot_type_str)\n",
    "    df = df.assign(shot_type_category=shot_type_cat)\n",
    "    df.drop(['type_of_shot', 'type_of_combined_shot'], axis = 1, inplace = True)  \n",
    "    \n",
    "    df = df.assign(sb = sb)\n",
    "    df = df.assign(ros = ros)\n",
    "    df = df.assign(aos = aos)\n",
    "    \n",
    "    df.drop(['range_of_shot', 'shot_basics', 'area_of_shot'], axis = 1, inplace = True) \n",
    "    \n",
    "                \n",
    "        \n",
    "    return df.groupby('match_id').progress_apply(custom_impute_fun)\n",
    "\n",
    "def split_dates(df):\n",
    "    for col in df.columns:\n",
    "        if col.find('date') != -1:\n",
    "            df[col] = pd.to_datetime(df[col])\n",
    "            df['Year'] = df[col].dt.year\n",
    "            df['Month'] = df[col].dt.month\n",
    "            df['Day'] = df[col].dt.day\n",
    "            df.drop(col, axis = 1, inplace =True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def preprocess_data(df, drop_cols = ['team_name', 'team_id', 'shot_id_number']):\n",
    "    # impute values\n",
    "    print('Imputing Values')\n",
    "    df = impute_values_groups(df)\n",
    "    \n",
    "    # drop useless columns\n",
    "    print('Dropping columns')\n",
    "    remove_cols(drop_cols, df)\n",
    "                \n",
    "    #Split date  columns into year, month , and day\n",
    "    df = split_dates(df)\n",
    "    \n",
    "    #Random FE\n",
    "    df = feature_engg(df)\n",
    "    \n",
    "    \n",
    "    # convert to str of respective columns for labelencoder\n",
    "    print('Converting types')\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype.kind == 'O':\n",
    "            print('Columns to str : ', col)\n",
    "            df[col] = df[col].str\n",
    "\n",
    "            \n",
    "    #LabelEncode\n",
    "    print('Encoding Values..')\n",
    "    df_encoded = df.progress_apply(LabelEncoder().fit_transform) \n",
    "    \n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_train.head(n = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.type_of_shot.isnull().sum(), len(data_train[(~data_train.type_of_shot.isnull()) & (~data_train.type_of_combined_shot.isnull())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_cols = ['power_of_shot', 'knockout_match', 'game_season', 'home/away', 'Year', 'Month', 'Day', 'shot_basics', 'lat', 'lng','area_of_shot','type_of_shot', 'type_of_combined_shot', 'power_of_shot.1', 'knockout_match.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = impute_values(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_en = preprocess_data(data_train)\n",
    "data_train_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = data_train_en.loc[:, data_train_en.columns != 'is_goal'], data_train_en['is_goal']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.01, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.drop(['is_goal'], inplace = True, axis = 1)\n",
    "text_x = preprocess_data(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = xgb.XGBClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C = 0.1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=300,max_depth= 3).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_cfl = VotingClassifier (\n",
    "        estimators = [('xgb', gbm), ('lt', lr), ('rf', rf)],\n",
    "                     voting='soft', weights = [1.33, 1, 1])\n",
    "vcfl = voting_cfl.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr.predict_proba(text_x)[:,1]#.max(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Features sorted by their score:\")\n",
    "for val in sorted(zip(map(lambda x: round(x, 4), gbm.feature_importances_), data_train_en.loc[:, data_train_en.columns != 'is_goal'].columns), \n",
    "             reverse=True):\n",
    "    print(val)\n",
    "# print(sorted(zip(map(lambda x: round(x, 4), gbm.feature_importances_), data_train_en.loc[:, data_train_en.columns != 'is_goal'].columns), \n",
    "#              reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = xgb.XGBClassifier()\n",
    "parameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['binary:logistic'],\n",
    "              'learning_rate': [0.01, 0.02, 0.03,0.1, 1], #so called `eta` value\n",
    "              'max_depth': [3,4,5,6,7,8],\n",
    "              'min_child_weight': [2,3,4,5,7],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.8],\n",
    "              'colsample_bytree': [0.5],\n",
    "              'n_estimators': [300, 400,500, 600], #number of trees\n",
    "              'seed': [1337],\n",
    "              'missing': [9999999999]}\n",
    "\n",
    "clf = GridSearchCV(gbm, parameters, n_jobs=2, \n",
    "                   cv=StratifiedKFold(n_splits=4, shuffle=True), \n",
    "                   verbose=2, refit=True,scoring='neg_mean_absolute_error')\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters, score = clf.best_params_ , clf.best_score_\n",
    "print('neg_mean_absolute_error:', score)\n",
    "for param_name in sorted(best_parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        \n",
    "mea = mean_absolute_error(y_train, clf.predict_proba(X_train)[:,1])\n",
    "print('Overall mean_absolute_error:', mea, 1/(1 + mea))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('\\n All results:')\n",
    "print(random_search.cv_results_)\n",
    "print('\\n Best estimator:')\n",
    "print(random_search.best_estimator_)\n",
    "print('\\n Best normalized gini score for %d-fold search with %d parameter combinations:' % (folds, param_comb))\n",
    "print(random_search.best_score_ * 2 - 1)\n",
    "print('\\n Best hyperparameters:')\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict_proba(text_x)[:,1]#.max(axis = 1)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.max(), predictions.min(), predictions.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_absolute_error(y_train, predictions), 1 / (1 + mean_absolute_error(y_train, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_final = predictions#.max(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossvaltest(params,train_set,train_label,cat_dims,n_splits=3):\n",
    "    kf = KFold(n_splits=n_splits,shuffle=True) \n",
    "    res = []\n",
    "    for train_index, test_index in kf.split(train_set):\n",
    "        train = train_set.iloc[train_index,:]\n",
    "        test = train_set.iloc[test_index,:]\n",
    "\n",
    "        labels = train_label.ix[train_index]\n",
    "        test_labels = train_label.ix[test_index]\n",
    "\n",
    "        clf = cb.CatBoostClassifier(**params)\n",
    "        clf.fit(train, np.ravel(labels), cat_features=cat_dims)\n",
    "\n",
    "        res.append(np.mean(clf.predict(test)==np.ravel(test_labels)))\n",
    "    return np.mean(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catboost_param_tune(params,train_set,train_label,cat_dims=None,n_splits=3):\n",
    "    ps = paramsearch(params)\n",
    "    # search 'border_count', 'l2_leaf_reg' etc. individually \n",
    "    #   but 'iterations','learning_rate' together\n",
    "    for prms in chain(ps.grid_search(['border_count']),\n",
    "                      ps.grid_search(['l2_leaf_reg']),\n",
    "                      ps.grid_search(['iterations','learning_rate']),\n",
    "                      ps.grid_search(['depth'])):\n",
    "        res = crossvaltest(prms,train_set,train_label,cat_dims,n_splits)\n",
    "        # save the crossvalidation result so that future iterations can reuse the best parameters\n",
    "        ps.register_result(res,prms)\n",
    "        print(res,prms,'best:',ps.bestscore(),ps.bestparam())\n",
    "    return ps.bestparam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = cb.CatBoostClassifier()#, loss_function='CrossEntropy')\n",
    "cat_dims = [X_train.columns.get_loc(i) for i in category_cols[:]] \n",
    "clf.fit(X_train, np.ravel(y_train), cat_features=cat_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict_proba(text_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_sub_df = pd.read_csv('data/sample_submission.csv')\n",
    "# sample_sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df['shot_id_number'] = pd.read_csv('data/sample_submission.csv')['shot_id_number']\n",
    "final_df = pd.DataFrame()\n",
    "final_df['shot_id_number'] = data_test['shot_id_number']\n",
    "final_df['is_goal'] = pred_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('submission14.csv', index =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prev_sub = pd.read_csv('submission2.csv')\n",
    "cur_sub = pd.read_csv('submission3_0.932.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_sub['is_goal'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_sub['is_goal'].dtype, cur_sub['is_goal'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(prev_sub['is_goal'] == cur_sub['is_goal']).sum() / len(prev_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "random_env",
   "language": "python",
   "name": "random_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
